

> current

- llama2
- gpt2


> llama3 gpt4o

- tokenizer:
	- 随着模型的演进，生成 token 数变少
	- openai 没有公开的秘密武器
	- 很多的 token 就是劣质的



> 多模态能力是怎么来的


- llava
- google 的 
- gpt4v
- llava-1.5 coglvm mitigpt-5


> 什么是多模态 ?

- everything is fucking embedding
- 从多个视角对事物进行表征

例子:
- 文本和图片
- 时间和空间
- 同一个文本在 使用不同的情感来说 ; 
- 一张图片是不是多模态 ?

处理多模态的难点:

- 定义: 从信息语义角度去区分 ;
- 表征: embedding 是基础，决定后续的 **高度** ;
- 对齐: `alignment` 
- 融合: 连接
- 迁移
- 协同学习:

> GPT-4o

- `4o`  的 encoder 有概率是 `3d` 的

> CNN 有2点 transformer 的独特优点

- 平移不变性
- 局部一致性


> VIT


> Flamingo

- 第一次提出了 crossAttention

> blip1 blip2

偷师了 Flamingo


> CLIP

> ALBEF 先对齐后融合


> BEIT - 多模态统一训练框架


> BLIP2-


> ..

- 